{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getting-started-on-colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Azf91OtajTab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61a1f20-889a-471b-b43a-4750124e48a4"
      },
      "cell_type": "code",
      "source": [
        "!apt update -qq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PKBV7iXgjdfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c716e9-cfa8-4ac2-8545-c791f79f3845"
      },
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-26 14:16:13--  https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://developer.nvidia.com/downloads/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb [following]\n",
            "--2023-05-26 14:16:14--  https://developer.nvidia.com/downloads/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
            "Reusing existing connection to developer.nvidia.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?PwYhkpViIunk5QC4nVFBR0hlkYqGKvRmkV-1BWYcN_jukWLQRif3ITZq8ygMDpuwDAtHjDX4jNVcvLHW6Ab77OqmzFWMvMFgIRS8-O-x96-jqRv71gaC9Ie3Q1cK4bV7XqWsVcPB-waMK-QVspfzS4TwsAakDaVHjqP96c_Dp-3M8xgMfBMcr5xN27g18nEwZAxZjh_W0ohjjngXSxdFIrDY5g== [following]\n",
            "--2023-05-26 14:16:15--  https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?PwYhkpViIunk5QC4nVFBR0hlkYqGKvRmkV-1BWYcN_jukWLQRif3ITZq8ygMDpuwDAtHjDX4jNVcvLHW6Ab77OqmzFWMvMFgIRS8-O-x96-jqRv71gaC9Ie3Q1cK4bV7XqWsVcPB-waMK-QVspfzS4TwsAakDaVHjqP96c_Dp-3M8xgMfBMcr5xN27g18nEwZAxZjh_W0ohjjngXSxdFIrDY5g==\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1913589814 (1.8G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.78G   243MB/s    in 7.1s    \n",
            "\n",
            "2023-05-26 14:16:22 (256 MB/s) - ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’ saved [1913589814/1913589814]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vrfKbLekdPDO"
      },
      "cell_type": "code",
      "source": [
        "!dpkg -i cuda-repo-ubuntu1604–8–0-local-ga2_8.0.61–1_amd64-deb 2> /dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A9Lo4FoydC7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f15df3-6e81-4140-9e66-ce7e71195e8e"
      },
      "cell_type": "code",
      "source": [
        "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpg: can't open '/var/cuda-repo-8-0-local-ga2/7fa2af80.pub': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vuIFPr-leAFV"
      },
      "cell_type": "code",
      "source": [
        "!apt-get update -qq"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5LCW1tnxj-pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6770f81a-876c-4a94-ce87-0dc5c8579675"
      },
      "cell_type": "code",
      "source": [
        "!apt --fix-broken install\n",
        "!apt-get install cuda gcc-5 g++-5 -y -qq;"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "E: Package 'gcc-5' has no installation candidate\n",
            "E: Package 'g++-5' has no installation candidate\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zoqglXEBj-02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5f43a7-2f2b-4a7a-af51-31346fa91cbf"
      },
      "cell_type": "code",
      "source": [
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n",
        "!apt install cuda-8.0;"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package cuda-8.0\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCouldn't find any package by glob 'cuda-8.0'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "IzaD9e62epuL"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ayx2gqk8iICV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5627f35-7d3a-485a-c3a7-02dcf0694a00"
      },
      "cell_type": "code",
      "source": [
        "!apt install gcc-5 g++-5 -y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package g++-5 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  gcc-10-test-results gcc-9-test-results gcc-8-test-results gcc-7-test-results\n",
            "\n",
            "Package gcc-5 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "\u001b[1;31mE: \u001b[0mPackage 'gcc-5' has no installation candidate\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mPackage 'g++-5' has no installation candidate\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MFe_6wdBiLcy"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1UT9EIGZiN12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb50ac5-4b2f-46d4-ff74-4f80354232c4"
      },
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zjr4TsIFk21Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4781db58-02a5-4221-a8ca-5037796725cd"
      },
      "cell_type": "code",
      "source": [
        "%%file version.cu\n",
        "#include <thrust/version.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int major = THRUST_MAJOR_VERSION;\n",
        "  int minor = THRUST_MINOR_VERSION;\n",
        "\n",
        "  std::cout << \"Thrust v\" << major << \".\" << minor << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing version.cu\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7lVHw-Ezlf_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554fefe6-8e05-424c-ac69-fa356a9c3f2b"
      },
      "cell_type": "code",
      "source": [
        "!nvcc version.cu -o version\n",
        "!./version"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thrust v1.15\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DXERV5wRlqX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96e50dc-c777-4551-e3e4-0925831d7867"
      },
      "cell_type": "code",
      "source": [
        "%%file thrust_example.cu\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <thrust/copy.h>\n",
        "#include <algorithm>\n",
        "#include <cstdlib>\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  // generate 32M random numbers serially\n",
        "  thrust::host_vector<int> h_vec(32 << 20);\n",
        "  std::generate(h_vec.begin(), h_vec.end(), rand);\n",
        "\n",
        "  // transfer data to the device\n",
        "  thrust::device_vector<int> d_vec = h_vec;\n",
        "\n",
        "  // sort data on the device \n",
        "  thrust::sort(d_vec.begin(), d_vec.end());\n",
        "\n",
        "  // transfer data back to host\n",
        "  thrust::copy(d_vec.begin(), d_vec.end(), h_vec.begin());\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing thrust_example.cu\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PSqPaE0amBwB"
      },
      "cell_type": "code",
      "source": [
        "!nvcc thrust_example.cu -o thrust_example\n",
        "!./thrust_example\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6gCqNHwmJp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b528f66a-ef8e-42c4-f532-ec8e3480757c"
      },
      "cell_type": "code",
      "source": [
        "!nvprof ./thrust_example"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2810== NVPROF is profiling process 2810, command: ./thrust_example\n",
            "==2810== Profiling application: ./thrust_example\n",
            "==2810== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   36.35%  28.594ms         1  28.594ms  28.594ms  28.594ms  [CUDA memcpy HtoD]\n",
            "                   35.97%  28.300ms         1  28.300ms  28.300ms  28.300ms  [CUDA memcpy DtoH]\n",
            "                   14.39%  11.320ms         3  3.7733ms  3.7660ms  3.7769ms  void cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=1, bool=0, int, cub::NullType, int>(cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *, cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=1, bool=0, int, cub::NullType, int>*, bool=1 const *, cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=1, bool=0, int, cub::NullType, int>**, bool=0*, cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=1, bool=0, int, cub::NullType, int>**, int, int, cub::GridEvenShare<cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=1, bool=0, int, cub::NullType, int>**>)\n",
            "                    7.93%  6.2380ms         2  3.1190ms  2.9498ms  3.2882ms  void cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=0, bool=0, int, cub::NullType, int>(cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *, cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=0, bool=0, int, cub::NullType, int>*, bool=0 const *, cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=0, bool=0, int, cub::NullType, int>**, bool=0*, cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=0, bool=0, int, cub::NullType, int>**, int, int, cub::GridEvenShare<cub::DeviceRadixSortDownsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=0, bool=0, int, cub::NullType, int>**>)\n",
            "                    2.26%  1.7791ms         3  593.05us  568.92us  608.47us  void cub::DeviceRadixSortUpsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=1, bool=0, int, int>(cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *, bool=1*, cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *, int, int, cub::GridEvenShare<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *>)\n",
            "                    1.52%  1.1951ms         2  597.56us  595.74us  599.38us  void cub::DeviceRadixSortUpsweepKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, bool=0, bool=0, int, int>(cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *, bool=0*, cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *, int, int, cub::GridEvenShare<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800 const *>)\n",
            "                    1.40%  1.0995ms         1  1.0995ms  1.0995ms  1.0995ms  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_cub::__parallel_for::ParallelForAgent<thrust::cuda_cub::__transform::unary_transform_f<int*, int*, thrust::cuda_cub::__transform::no_stencil_tag, thrust::identity<int>, thrust::cuda_cub::__transform::always_true_predicate>, long>, thrust::cuda_cub::__transform::unary_transform_f<int*, int*, thrust::cuda_cub::__transform::no_stencil_tag, thrust::identity<int>, thrust::cuda_cub::__transform::always_true_predicate>, long>(int*, thrust::cuda_cub::__transform::no_stencil_tag)\n",
            "                    0.18%  144.38us         5  28.876us  24.543us  35.295us  void cub::RadixSortScanBinsKernel<cub::DeviceRadixSortPolicy<int, cub::NullType, int>::Policy800, int>(cub::NullType*, int)\n",
            "      API calls:   73.56%  226.17ms         2  113.08ms  276.21us  225.89ms  cudaMalloc\n",
            "                   18.71%  57.526ms         2  28.763ms  28.692ms  28.834ms  cudaMemcpyAsync\n",
            "                    7.09%  21.806ms         4  5.4516ms  2.9610us  21.715ms  cudaStreamSynchronize\n",
            "                    0.35%  1.0643ms         1  1.0643ms  1.0643ms  1.0643ms  cuDeviceGetPCIBusId\n",
            "                    0.18%  568.65us         2  284.33us  233.01us  335.64us  cudaFree\n",
            "                    0.04%  110.45us       101  1.0930us     124ns  46.994us  cuDeviceGetAttribute\n",
            "                    0.03%  99.231us        16  6.2010us  3.4350us  29.502us  cudaLaunchKernel\n",
            "                    0.02%  55.310us         1  55.310us  55.310us  55.310us  cudaFuncGetAttributes\n",
            "                    0.01%  23.135us         1  23.135us  23.135us  23.135us  cuDeviceGetName\n",
            "                    0.00%  10.586us        76     139ns     114ns     569ns  cudaGetLastError\n",
            "                    0.00%  9.1890us        12     765ns     388ns  2.7400us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags\n",
            "                    0.00%  4.4050us         7     629ns     269ns  1.8710us  cudaGetDevice\n",
            "                    0.00%  4.3290us        32     135ns     115ns     201ns  cudaPeekAtLastError\n",
            "                    0.00%  2.8660us         3     955ns     500ns  1.5680us  cudaDeviceGetAttribute\n",
            "                    0.00%  1.8370us         3     612ns     253ns  1.2430us  cuDeviceGetCount\n",
            "                    0.00%  1.0230us         2     511ns     202ns     821ns  cuDeviceGet\n",
            "                    0.00%     593ns         1     593ns     593ns     593ns  cuDeviceTotalMem\n",
            "                    0.00%     560ns         1     560ns     560ns     560ns  cuModuleGetLoadingMode\n",
            "                    0.00%     260ns         1     260ns     260ns     260ns  cudaGetDeviceCount\n",
            "                    0.00%     215ns         1     215ns     215ns     215ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nKymLb9hnFIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bf77b7-4397-488d-d975-c189d0e33ca6"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-3ok1yhmo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-3ok1yhmo\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=561853c2d90701fb2a749aca0fe1b2a4f1d11fa19846f30d7512abd8a082537a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-25181hz9/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3procQsbQVB",
        "outputId": "425139ca-b927-402d-a32c-a76bc08b87e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "__global__ void matadd(int *l,int *m, int *n)\n",
        "{\n",
        "    int x=blockIdx.x;\n",
        "    int y=blockIdx.y;\n",
        "    int id=gridDim.x * y +x;\n",
        "    n[id]=l[id]+m[id];\n",
        "}\n",
        "int main()\n",
        "{\n",
        "    int a[2][3];\n",
        "    int b[2][3];\n",
        "    int c[2][3];\n",
        "    int *d,*e,*f;\n",
        "    int i,j;\n",
        "    printf(\"\\n Enter elements of first matrix of size 2 * 3\\n\");\n",
        "    for(i=0;i<2;i++)\n",
        "    {\n",
        "        for(j=0;j<3;j++)\n",
        "            {\n",
        "                scanf(\"%d\",&a[i][j]);\n",
        "            }\n",
        "    }\n",
        "    printf(\"\\n Enter elements of second matrix of size 2 * 3\\n\");\n",
        "        for(i=0;i<2;i++)\n",
        "        {\n",
        "            for(j=0;j<3;j++)\n",
        "                {\n",
        "                    scanf(\"%d\",&b[i][j]);\n",
        "                }\n",
        "        }\n",
        "    cudaMalloc((void **)&d,2*3*sizeof(int));\n",
        "    cudaMalloc((void **)&e,2*3*sizeof(int));\n",
        "    cudaMalloc((void **)&f,2*3*sizeof(int));\n",
        " cudaMemcpy(d,a,2*3*sizeof(int),cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(e,b,2*3*sizeof(int),cudaMemcpyHostToDevice);\n",
        "    \n",
        "dim3 grid(3,2);\n",
        "/* Here we are defining two dimensional Grid(collection of blocks) structure. Syntax is dim3 grid(no. of columns,no. of rows) */\n",
        "\n",
        "    matadd<<<grid,1>>>(d,e,f);\n",
        "\n",
        " cudaMemcpy(c,f,2*3*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    printf(\"\\nSum of two matrices:\\n \");\n",
        "    for(i=0;i<2;i++)\n",
        "    {\n",
        "        for(j=0;j<3;j++)\n",
        "        {\n",
        "              printf(\"%d\\t\",c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaFree(d);\n",
        "    cudaFree(e);\n",
        "    cudaFree(f);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc54EobybptR",
        "outputId": "a40d36b2-603b-49ff-f3aa-84ef20dbb2f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Enter elements of first matrix of size 2 * 3\n",
            "\n",
            " Enter elements of second matrix of size 2 * 3\n",
            "\n",
            "Sum of two matrices:\n",
            " 1755345044\t32766\t-371698876\t\n",
            "44084\t-465744152\t32756\t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "\n",
        "__global__ void arradd(int *x,int *y, int *z)    //kernel definition\n",
        "{\n",
        "  int id=blockIdx.x; \n",
        "/* blockIdx.x gives the respective block id which starts from 0 */\n",
        "  z[id]=x[id]+y[id];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int a[6];\n",
        "    int b[6];\n",
        "    int c[6];\n",
        "    int *d,*e,*f;\n",
        "    int i;\n",
        "    printf(\"\\n Enter six elements of first array\\n\");\n",
        "    for(i=0;i<6;i++)\n",
        "    {\n",
        "        scanf(\"%d\",&a[i]);\n",
        "    }\n",
        "    printf(\"\\n Enter six elements of second array\\n\");\n",
        "        for(i=0;i<6;i++)\n",
        "        {\n",
        "            scanf(\"%d\",&b[i]);\n",
        "        }\n",
        "\n",
        "/* cudaMalloc() allocates memory from Global memory on GPU */\n",
        "    cudaMalloc((void **)&d,6*sizeof(int));\n",
        "    cudaMalloc((void **)&e,6*sizeof(int));\n",
        "    cudaMalloc((void **)&f,6*sizeof(int));\n",
        "\n",
        "/* cudaMemcpy() copies the contents from destination to source. Here destination is GPU(d,e) and source is CPU(a,b) */\n",
        " cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);   \n",
        " cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);\n",
        " \n",
        "/* call to kernel. Here 6 is number of blocks, 1 is the number of threads per block and d,e,f are the arguments */ \n",
        "arradd<<<6,1>>>(d,e,f); \n",
        "\n",
        "/* Here we are copying content from GPU(Device) to CPU(Host) */\n",
        " cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    \n",
        "printf(\"\\nSum of two arrays:\\n \");\n",
        "    for(i=0;i<6;i++)\n",
        "    {\n",
        "        printf(\"%d\\t\",c[i]);\n",
        "    }\n",
        "\n",
        "/* Free the memory allocated to pointers d,e,f */\n",
        "    cudaFree(d);\n",
        "    cudaFree(e);\n",
        "    cudaFree(f);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUk05rkb3hY",
        "outputId": "0ab380d5-9bed-4df5-f87c-a52500d86949"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Enter six elements of first array\n",
            "\n",
            " Enter six elements of second array\n",
            "\n",
            "Sum of two arrays:\n",
            " 1612409572\t32764\t399503882\t43996\t-1737330968\t32596\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "#include \"stdio.h\"\n",
        "int main()\n",
        "{\n",
        "    printf(\"Hello world\");\n",
        " return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgS4_YUWcELy",
        "outputId": "e4cc4458-b602-4e87-beb9-6c9a0c264dd1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#define N 3\n",
        "__global__ void matrixMultiplication(float *A, float *B, float *C, int n)\n",
        "{\n",
        "int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "if (i < n && j < n) {\n",
        "float sum = 0.0f;\n",
        "for (int k = 0; k < n; ++k) {\n",
        "sum += A[i * n + k] * B[k * n + j];\n",
        "}\n",
        "C[i * n + j] = sum;\n",
        "}\n",
        "}\n",
        "int main()\n",
        "{\n",
        "float A[N][N] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "float B[N][N] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "float C[N][N] = {0};\n",
        "// Allocate device memory\n",
        "float *d_A, *d_B, *d_C;\n",
        "cudaMalloc(&d_A, N * N * sizeof(float));\n",
        "cudaMalloc(&d_B, N * N * sizeof(float));\n",
        "cudaMalloc(&d_C, N * N * sizeof(float));\n",
        "// Copy input matrices from host to device\n",
        "cudaMemcpy(d_A, A, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(d_B, B, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "// Set the grid and block dimensions\n",
        "dim3 gridDim(ceil(N/16.0), ceil(N/16.0), 1);\n",
        "dim3 blockDim(16, 16, 1);\n",
        "// Launch the kernel\n",
        "matrixMultiplication<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n",
        "// Copy result matrix from device to host\n",
        "cudaMemcpy(C, d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "// Print the result matrix\n",
        "\n",
        "printf(\"Result Matrix:\\n\");\n",
        "for (int i = 0; i < N; ++i) {\n",
        "for (int j = 0; j < N; ++j) {\n",
        "printf(\"%.1f \", C[i][j]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}\n",
        "// Free device memory\n",
        "cudaFree(d_A);\n",
        "cudaFree(d_B);\n",
        "cudaFree(d_C);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjJv5L-GcKF5",
        "outputId": "d426cdcc-9cb4-48a3-9bcc-8c539b00c7c1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result Matrix:\n",
            "30.0 24.0 18.0 \n",
            "84.0 69.0 54.0 \n",
            "138.0 114.0 90.0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define N 5\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "if (i < N) {\n",
        "c[i] = a[i] + b[i];\n",
        "}\n",
        "}\n",
        "int main() {\n",
        "int a[N] = {1, 2, 3, 4, 5};\n",
        "int b[N] = {6, 7, 8, 9, 10};\n",
        "int c[N] = {0};\n",
        "int *dev_a, *dev_b, *dev_c;\n",
        "cudaMalloc((void **)&dev_a, N * sizeof(int));\n",
        "cudaMalloc((void **)&dev_b, N * sizeof(int));\n",
        "cudaMalloc((void **)&dev_c, N * sizeof(int));\n",
        "cudaMemcpy(dev_a, a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(dev_b, b, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "add<<<1, N>>>(dev_a, dev_b, dev_c);\n",
        "cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "for (int i = 0; i < N; i++) {\n",
        "//printf(\"%d \", c[i]);\n",
        "printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "cudaFree(dev_a);\n",
        "cudaFree(dev_b);\n",
        "cudaFree(dev_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "y9dFbtC4cyGw",
        "outputId": "f4723cd5-2656-4a82-f220-f918a468c527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 + 6 = 7\n",
            "2 + 7 = 9\n",
            "3 + 8 = 11\n",
            "4 + 9 = 13\n",
            "5 + 10 = 15\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}